{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNI56zchLAup"
      },
      "source": [
        "# Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOCo4h08K9Jy"
      },
      "outputs": [],
      "source": [
        "import types\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "\n",
        "\n",
        "def CountSketchFn_forward(h, s, output_size, x, force_cpu_scatter_add=False):\n",
        "    x_size = tuple(x.size())\n",
        "\n",
        "    s_view = (1,) * (len(x_size) - 1) + (x_size[-1],)\n",
        "\n",
        "    out_size = x_size[:-1] + (output_size,)\n",
        "\n",
        "    # Broadcast s and compute x * s\n",
        "    s = s.view(s_view)\n",
        "    xs = x * s\n",
        "\n",
        "    # Broadcast h then compute h:\n",
        "    # out[h_i] += x_i * s_i\n",
        "    h = h.view(s_view).expand(x_size)\n",
        "\n",
        "    if force_cpu_scatter_add:\n",
        "        out = x.new(*out_size).zero_().cpu()\n",
        "        return out.scatter_add_(-1, h.cpu(), xs.cpu()).cuda()\n",
        "    else:\n",
        "        out = x.new(*out_size).zero_()\n",
        "        return out.scatter_add_(-1, h, xs)\n",
        "\n",
        "\n",
        "def CountSketchFn_backward(h, s, x_size, grad_output):\n",
        "    s_view = (1,) * (len(x_size) - 1) + (x_size[-1],)\n",
        "\n",
        "    s = s.view(s_view)\n",
        "    h = h.view(s_view).expand(x_size)\n",
        "\n",
        "    grad_x = grad_output.gather(-1, h)\n",
        "    grad_x = grad_x * s\n",
        "    return grad_x\n",
        "\n",
        "\n",
        "class CountSketchFn(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, h, s, output_size, x, force_cpu_scatter_add=False):\n",
        "        x_size = tuple(x.size())\n",
        "\n",
        "        ctx.save_for_backward(h, s)\n",
        "        ctx.x_size = tuple(x.size())\n",
        "\n",
        "        return CountSketchFn_forward(h, s, output_size, x, force_cpu_scatter_add)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        h, s = ctx.saved_variables\n",
        "\n",
        "        grad_x = CountSketchFn_backward(h, s, ctx.x_size, grad_output)\n",
        "        return None, None, None, grad_x\n",
        "\n",
        "\n",
        "class CountSketch(nn.Module):\n",
        "    r\"\"\"Compute the count sketch over an input signal.\n",
        "\n",
        "    .. math::\n",
        "\n",
        "        out_j = \\sum_{i : j = h_i} s_i x_i\n",
        "\n",
        "    Args:\n",
        "        input_size (int): Number of channels in the input array\n",
        "        output_size (int): Number of channels in the output sketch\n",
        "        h (array, optional): Optional array of size input_size of indices in the range [0,output_size]\n",
        "        s (array, optional): Optional array of size input_size of -1 and 1.\n",
        "\n",
        "    .. note::\n",
        "\n",
        "        If h and s are None, they will be automatically be generated using LongTensor.random_.\n",
        "\n",
        "    Shape:\n",
        "        - Input: (...,input_size)\n",
        "        - Output: (...,output_size)\n",
        "\n",
        "    References:\n",
        "        Yang Gao et al. \"Compact Bilinear Pooling\" in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (2016).\n",
        "        Akira Fukui et al. \"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\", arXiv:1606.01847 (2016).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, output_size, h=None, s=None):\n",
        "        super(CountSketch, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        if h is None:\n",
        "            h = torch.LongTensor(input_size).random_(0, output_size)\n",
        "        if s is None:\n",
        "            s = 2 * torch.Tensor(input_size).random_(0, 2) - 1\n",
        "\n",
        "        # The Variable h being a list of indices,\n",
        "        # If the type of this module is changed (e.g. float to double),\n",
        "        # the variable h should remain a LongTensor\n",
        "        # therefore we force float() and double() to be no-ops on the variable h.\n",
        "        def identity(self):\n",
        "            return self\n",
        "\n",
        "        h.float = types.MethodType(identity, h)\n",
        "        h.double = types.MethodType(identity, h)\n",
        "\n",
        "        self.register_buffer('h', h)\n",
        "        self.register_buffer('s', s)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = list(x.size())\n",
        "\n",
        "        assert (x_size[-1] == self.input_size)\n",
        "\n",
        "        return CountSketchFn.apply(self.h, self.s, self.output_size, x)\n",
        "\n",
        "\n",
        "def ComplexMultiply_forward(X_re, X_im, Y_re, Y_im):\n",
        "    Z_re = torch.addcmul(X_re * Y_re, X_im, Y_im, value= -1)\n",
        "    Z_im = torch.addcmul(X_re * Y_im, X_im, Y_re, value= 1)\n",
        "    return Z_re, Z_im\n",
        "\n",
        "\n",
        "def ComplexMultiply_backward(x_re, x_im, y_re, y_im, grad_z_re, grad_z_im):\n",
        "    grad_x_re = torch.addcmul(grad_z_re * y_re, grad_z_im, y_im, value= 1)\n",
        "    grad_x_im = torch.addcmul(grad_z_im * y_re, grad_z_re, y_im, value= -1)\n",
        "    grad_y_re = torch.addcmul(grad_z_re * x_re, grad_z_im, x_im, value= 1)\n",
        "    grad_y_im = torch.addcmul(grad_z_im * x_re, grad_z_re, x_im, value= -1)\n",
        "    return grad_x_re, grad_x_im, grad_y_re, grad_y_im\n",
        "\n",
        "\n",
        "class ComplexMultiply(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x_re, x_im, y_re, y_im):\n",
        "        ctx.save_for_backward(x_re, x_im, y_re, y_im)\n",
        "        return ComplexMultiply_forward(x_re, x_im, y_re, y_im)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_z_re, grad_z_im):\n",
        "        x_re, x_im, y_re, y_im = ctx.saved_tensors\n",
        "        return ComplexMultiply_backward(x_re, x_im, y_re, y_im, grad_z_re, grad_z_im)\n",
        "\n",
        "\n",
        "class CompactBilinearPoolingFn(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, h1, s1, h2, s2, output_size, x, y, force_cpu_scatter_add=False):\n",
        "        ctx.save_for_backward(h1, s1, h2, s2, x, y)\n",
        "        ctx.x_size = tuple(x.size())\n",
        "        ctx.y_size = tuple(y.size())\n",
        "        ctx.force_cpu_scatter_add = force_cpu_scatter_add\n",
        "        ctx.output_size = output_size\n",
        "\n",
        "        # Compute the count sketch of each input: x ==> px, y ==> py\n",
        "        px = CountSketchFn_forward(h1, s1, output_size, x, force_cpu_scatter_add)\n",
        "        fx = torch.fft.rfft(px, dim=1)\n",
        "        fx_re = fx.real\n",
        "        fx_im = fx.imag\n",
        "        del px\n",
        "        py = CountSketchFn_forward(h2, s2, output_size, y, force_cpu_scatter_add)\n",
        "        fy = torch.fft.rfft(py, dim=1)\n",
        "        fy_re = fy.real\n",
        "        fy_im = fy.imag\n",
        "        del py\n",
        "\n",
        "        # Convolution of the two sketch using an FFT.\n",
        "        # Compute the FFT of each sketch\n",
        "\n",
        "        # Complex multiplication: element-wise product\n",
        "        prod_re, prod_im = ComplexMultiply_forward(fx_re, fx_im, fy_re, fy_im)\n",
        "        complex_prod = torch.complex(prod_re, prod_im)\n",
        "\n",
        "        # Back to real domain\n",
        "        # The imaginary part should be zero's\n",
        "        re = torch.fft.irfft(complex_prod, n=output_size)\n",
        "\n",
        "        return re\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        h1, s1, h2, s2, x, y = ctx.saved_tensors\n",
        "\n",
        "        # Recompute part of the forward pass to get the input to the complex product\n",
        "        # Compute the count sketch of each input\n",
        "        px = CountSketchFn_forward(h1, s1, ctx.output_size, x, ctx.force_cpu_scatter_add)\n",
        "        py = CountSketchFn_forward(h2, s2, ctx.output_size, y, ctx.force_cpu_scatter_add)\n",
        "\n",
        "        # Then convert the output to Fourier domain\n",
        "        grad_output = grad_output.contiguous()\n",
        "        grad_prod = torch.fft.rfft(grad_output, dim=1)\n",
        "        grad_re_prod = grad_prod.real\n",
        "        grad_im_prod = grad_prod.imag\n",
        "\n",
        "        # Compute the gradient of x first then y\n",
        "\n",
        "        # Gradient of x\n",
        "        # Recompute fy\n",
        "        fy = torch.fft.rfft(py, dim=1)\n",
        "        re_fy = fy.real\n",
        "        im_fy = fy.imag\n",
        "        del py\n",
        "        # Compute the gradient of fx, then back to temporal space\n",
        "        grad_re_fx = torch.addcmul(grad_re_prod * re_fy, grad_im_prod, im_fy, value= 1)\n",
        "        grad_im_fx = torch.addcmul(grad_im_prod * re_fy, grad_re_prod, im_fy, value= -1)\n",
        "        complex_fx = torch.complex(grad_re_fx, grad_im_fx)\n",
        "        grad_fx = torch.fft.irfft(complex_fx, n=ctx.output_size)\n",
        "        # Finally compute the gradient of x\n",
        "        grad_x = CountSketchFn_backward(h1, s1, ctx.x_size, grad_fx)\n",
        "        del re_fy, im_fy, grad_re_fx, grad_im_fx, grad_fx\n",
        "\n",
        "        # Gradient of y\n",
        "        # Recompute fx\n",
        "        fx = torch.fft.rfft(px, dim=1)\n",
        "        re_fx = fx.real\n",
        "        im_fx = fx.imag\n",
        "        del px\n",
        "        # Compute the gradient of fy, then back to temporal space\n",
        "        grad_re_fy = torch.addcmul(grad_re_prod * re_fx, grad_im_prod, im_fx, value= 1)\n",
        "        grad_im_fy = torch.addcmul(grad_im_prod * re_fx, grad_re_prod, im_fx, value= -1)\n",
        "        complex_fy = torch.complex(grad_re_fy, grad_im_fy)\n",
        "        grad_fy = torch.fft.irfft(complex_fy, n=ctx.output_size)\n",
        "        # Finally compute the gradient of y\n",
        "        grad_y = CountSketchFn_backward(h2, s2, ctx.y_size, grad_fy)\n",
        "        del re_fx, im_fx, grad_re_fy, grad_im_fy, grad_fy\n",
        "\n",
        "        return None, None, None, None, None, grad_x, grad_y, None\n",
        "\n",
        "\n",
        "class CompactBilinearPooling(nn.Module):\n",
        "    r\"\"\"Compute the compact bilinear pooling between two input array x and y\n",
        "\n",
        "    .. math::\n",
        "\n",
        "        out = \\Psi (x,h_1,s_1) \\ast \\Psi (y,h_2,s_2)\n",
        "\n",
        "    Args:\n",
        "        input_size1 (int): Number of channels in the first input array\n",
        "        input_size2 (int): Number of channels in the second input array\n",
        "        output_size (int): Number of channels in the output array\n",
        "        h1 (array, optional): Optional array of size input_size of indices in the range [0,output_size]\n",
        "        s1 (array, optional): Optional array of size input_size of -1 and 1.\n",
        "        h2 (array, optional): Optional array of size input_size of indices in the range [0,output_size]\n",
        "        s2 (array, optional): Optional array of size input_size of -1 and 1.\n",
        "        force_cpu_scatter_add (boolean, optional): Force the scatter_add operation to run on CPU for testing purposes\n",
        "\n",
        "    .. note::\n",
        "\n",
        "        If h1, s1, s2, h2 are None, they will be automatically be generated using LongTensor.random_.\n",
        "\n",
        "    Shape:\n",
        "        - Input 1: (...,input_size1)\n",
        "        - Input 2: (...,input_size2)\n",
        "        - Output: (...,output_size)\n",
        "\n",
        "    References:\n",
        "        Yang Gao et al. \"Compact Bilinear Pooling\" in Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (2016).\n",
        "        Akira Fukui et al. \"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\", arXiv:1606.01847 (2016).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input1_size, input2_size, output_size, h1=None, s1=None, h2=None, s2=None,\n",
        "                 force_cpu_scatter_add=False):\n",
        "        super(CompactBilinearPooling, self).__init__()\n",
        "        self.add_module('sketch1', CountSketch(input1_size, output_size, h1, s1))\n",
        "        self.add_module('sketch2', CountSketch(input2_size, output_size, h2, s2))\n",
        "        self.output_size = output_size\n",
        "        self.force_cpu_scatter_add = force_cpu_scatter_add\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        if y is None:\n",
        "            y = x\n",
        "        return CompactBilinearPoolingFn.apply(self.sketch1.h, self.sketch1.s, self.sketch2.h, self.sketch2.s,\n",
        "                                              self.output_size, x, y, self.force_cpu_scatter_add)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxZZvQBKK2Li"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "from torch.autograd import Function\n",
        "import math\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "import scipy\n",
        "from scipy import stats\n",
        "from scipy.optimize import curve_fit\n",
        "import random\n",
        "import time\n",
        "\n",
        "\n",
        "def logistic_func(X, bayta1, bayta2, bayta3, bayta4):\n",
        "    denominator = np.abs(bayta4) + 1e-5  # to avoid division by zero\n",
        "    numerator = np.negative(X - bayta3)\n",
        "    exponent = np.clip(np.divide(numerator, denominator), -500, 500)  # to avoid overflow and underflow\n",
        "    logisticPart = 1 + np.exp(exponent)\n",
        "    yhat = bayta2 + np.divide(bayta1 - bayta2, logisticPart)\n",
        "    return yhat\n",
        "\n",
        "\n",
        "def fit_function(y_label, y_output):\n",
        "    max_val = np.max(y_label)\n",
        "    min_val = np.min(y_label)\n",
        "    mean_val = np.mean(y_output)\n",
        "    range_val = np.max(y_output) - np.min(y_output)\n",
        "    beta = [max_val, min_val, mean_val, range_val]\n",
        "    popt, _ = curve_fit(logistic_func, y_output, y_label, p0=beta, maxfev=1000000)\n",
        "    y_output_logistic = logistic_func(y_output, *popt)\n",
        "    return y_output_logistic\n",
        "\n",
        "\n",
        "class Conv1x1WeightedSum(nn.Module):\n",
        "    def __init__(self, input_dim_1, input_dim_2, output_dim):\n",
        "        super(Conv1x1WeightedSum, self).__init__()\n",
        "        self.conv = nn.Conv1d(input_dim_1 + input_dim_2, output_dim, 1)\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(output_size=1)\n",
        "        self.batch_norm = nn.BatchNorm1d(output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # reshape the input tensors to (batch_size, channels, sequence_length)\n",
        "        x1 = x1.view(x1.size(0), x1.size(1), -1)\n",
        "        x2 = x2.view(x2.size(0), x2.size(1), -1)\n",
        "        # concatenate the two feature vectors along the channel dimension\n",
        "        x = torch.cat((x1, x2), dim=1)\n",
        "        # apply a 1x1 convolutional layer to generate weights\n",
        "        weights = self.sigmoid(self.conv(x))\n",
        "        # compute the weighted sum of the two feature vectors\n",
        "        output = weights * x1 + (1 - weights) * x2\n",
        "        # apply global average pooling to the output tensor\n",
        "        output = self.global_pool(output)\n",
        "        # apply batch normalization to the output tensor\n",
        "        output = self.batch_norm(output.squeeze(-1))\n",
        "        return output\n",
        "\n",
        "\n",
        "class MultiplyFeatureVectors(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(MultiplyFeatureVectors, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=in_features, out_channels=in_features, kernel_size=1)\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(output_size=1)\n",
        "        self.batch_norm = nn.BatchNorm1d(in_features)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # concatenate the two feature vectors along the channel dimension\n",
        "        x = torch.cat([x1.unsqueeze(2), x2.unsqueeze(2)], dim=2)\n",
        "        # apply a 1D convolutional layer to the concatenated tensor\n",
        "        output = self.conv1(x)\n",
        "        # apply global average pooling to the output tensor\n",
        "        output = self.global_pool(output)\n",
        "        # apply batch normalization to the output tensor\n",
        "        output = self.batch_norm(output)\n",
        "        return output.squeeze()\n",
        "\n",
        "def global_std_pool2d(x):\n",
        "    \"\"\"2D global standard variation pooling\"\"\"\n",
        "    return torch.std(x.view(x.size()[0], x.size()[1], -1, 1),\n",
        "                     dim=2, keepdim=True)\n",
        "\n",
        "\n",
        "__all__ = ['myResNet', 'myresnet18', 'myresnet34', 'myresnet50', 'myresnet101',\n",
        "           'myresnet152', 'myresnext50_32x4d', 'myresnext101_32x8d',\n",
        "           'mywide_resnet50_2', 'mywide_resnet101_2']\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
        "}\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class myResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, feature_fusion_method, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(myResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "\n",
        "        self.bn_img = nn.BatchNorm1d(128)\n",
        "        self.bn_video = nn.BatchNorm1d(128)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        if feature_fusion_method==0:\n",
        "            print(\"[WARN]: Feature Fusion By Concat\")\n",
        "            self.adjust1 = nn.Linear(2048,128)\n",
        "            self.adjust2 = nn.Linear(256,128)\n",
        "            self.quality = nn.Linear(128+128,1)\n",
        "            self.feature_fusion = self.concat_\n",
        "        elif feature_fusion_method==1:\n",
        "            print(\"[WARN]: Feature Fusion By Multiply\")\n",
        "            self.adjust1 = nn.Linear(2048,128)\n",
        "            self.adjust2 = nn.Linear(256,128)\n",
        "            self.feature_fusion = self.multiply\n",
        "            self.fconv = MultiplyFeatureVectors(128)\n",
        "            self.quality = nn.Linear(128,1)\n",
        "        elif feature_fusion_method==2:\n",
        "            print(\"[WARN]: Feature Fusion By 1x1Conv\")\n",
        "            self.adjust1 = nn.Linear(2048,128)\n",
        "            self.adjust2 = nn.Linear(256,128)\n",
        "            self.fconv = Conv1x1WeightedSum(128,128,128)\n",
        "            self.feature_fusion = self.convolve1x1\n",
        "            self.quality = nn.Linear(128,1)\n",
        "        elif feature_fusion_method==3:\n",
        "            print(\"[WARN]: Feature Fusion By CompactMultiLinearPooling\")\n",
        "            self.fconv = CompactBilinearPooling(256,256,512)\n",
        "            self.adjust1 = nn.Linear(2048,256)\n",
        "            self.bn_img = nn.BatchNorm1d(256)\n",
        "            self.feature_fusion = self.cmap\n",
        "            self.quality = nn.Linear(512,1)\n",
        "\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def flatten(self, itensors):\n",
        "        itensors[0] = torch.flatten(itensors[0],1)\n",
        "        itensors[1] = torch.flatten(itensors[1],1)\n",
        "        return itensors\n",
        "\n",
        "    def normalize(self, itensors):\n",
        "        itensors[0] = self.bn_img((self.adjust1(itensors[0])))\n",
        "        itensors[1] = self.bn_video(self.adjust2(itensors[1]))\n",
        "        return itensors\n",
        "\n",
        "    def concat_(self,itensors,**kwargs):\n",
        "        itensors = self.flatten(itensors)\n",
        "        itensors = self.normalize(itensors)\n",
        "        return torch.cat(tuple(itensors),dim=1)\n",
        "\n",
        "    def multiply(self,itensors,**kwargs):\n",
        "        itensors = self.flatten(itensors)\n",
        "        itensors = self.normalize(itensors)\n",
        "        return self.fconv(itensors[0],itensors[1])\n",
        "\n",
        "    def convolve1x1(self,itensors,**kwargs):\n",
        "        itensors = self.flatten(itensors)\n",
        "        itensors = self.normalize(itensors)\n",
        "        return self.fconv(itensors[0],itensors[1])\n",
        "\n",
        "    def cmap(self,itensors,**kwargs):\n",
        "      itensors = self.flatten(itensors)\n",
        "      itensors[0] = self.bn_img((self.adjust1(itensors[0])))\n",
        "      return self.fconv(itensors[0], itensors[1])\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def quality_pred(self,in_channels,middle_channels,out_channels):\n",
        "        regression_block = nn.Sequential(\n",
        "            nn.Linear(in_channels, middle_channels),\n",
        "            nn.Linear(middle_channels, out_channels),\n",
        "        )\n",
        "\n",
        "        return regression_block\n",
        "\n",
        "    def hyper_structure1(self,in_channels,out_channels):\n",
        "\n",
        "        hyper_block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels,in_channels//4,kernel_size=1,stride=1, padding=0,bias=False),\n",
        "            nn.Conv2d(in_channels//4,in_channels//4,kernel_size=3,stride=1, padding=1,bias=False),\n",
        "            nn.Conv2d(in_channels//4,out_channels,kernel_size=1,stride=1, padding=0,bias=False),\n",
        "        )\n",
        "\n",
        "        return hyper_block\n",
        "\n",
        "    def hyper_structure2(self,in_channels,out_channels):\n",
        "        hyper_block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels,in_channels//4,kernel_size=1,stride=1, padding=0,bias=False),\n",
        "            nn.Conv2d(in_channels//4,in_channels//4,kernel_size=3,stride=2, padding=1,bias=False),\n",
        "            nn.Conv2d(in_channels//4,out_channels,kernel_size=1,stride=1, padding=0,bias=False),\n",
        "        )\n",
        "\n",
        "        return hyper_block\n",
        "\n",
        "\n",
        "    def forward(self, x, x_fast_features):\n",
        "        x_size = x.shape\n",
        "        x_fast_features_size = x_fast_features.shape\n",
        "        x = x.view(-1, x_size[2], x_size[3], x_size[4])\n",
        "        x_fast_features = x_fast_features.view(-1, x_fast_features_size[2])\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        # This is where we would mess around with the feature vector adaptation\n",
        "        #x = torch.cat((self.bn_img((self.adjust1(x))), self.bn_video(self.adjust2(x_fast_features))), dim=1)\n",
        "        x = self.feature_fusion([x,x_fast_features], dim=1,x_size=x_size)\n",
        "        output = self.quality(x)\n",
        "        output = output.view(x_size[0],x_size[1])\n",
        "        output = torch.mean(output,dim=1)\n",
        "        return output\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = myResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def myresnet18(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "def myresnet34(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-34 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    model = myResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        # model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "        model_dict = model.state_dict()\n",
        "        pre_train_model = model_zoo.load_url(model_urls['resnet34'])\n",
        "        pre_train_model = {k:v for k,v in pre_train_model.items() if k in model_dict}\n",
        "        model_dict.update(pre_train_model)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def myresnet50(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"myResNet-50 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    print(kwargs)\n",
        "    model = myResNet(Bottleneck, [3, 4, 6, 3], feature_fusion_method=kwargs.pop('feature_fusion_method',0))\n",
        "    # input = torch.randn(1, 3, 224, 224)\n",
        "    # flops, params = profile(model, inputs=(input, ))\n",
        "    # print('The flops is {:.4f}, and the params is {:.4f}'.format(flops/10e9, params/10e6))\n",
        "    if pretrained:\n",
        "        # model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "        model_dict = model.state_dict()\n",
        "        pre_train_model = model_zoo.load_url(model_urls['resnet50'])\n",
        "        # pre_train_model = torch.load('./base_ckpts/ResNet_mean_std_MTL_epoch_30_accu_0.963589.pth')\n",
        "        # print (pre_train_model.items())\n",
        "        pre_train_model = {k:v for k,v in pre_train_model.items() if k in model_dict and not ('branch_' in k)}\n",
        "        model_dict.update(pre_train_model)\n",
        "        model.load_state_dict(model_dict)\n",
        "        print ('load the pretrained model, doneÔºÅ')\n",
        "    return model\n",
        "\n",
        "\n",
        "def myresnet101(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-101 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    # return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress,\n",
        "    #                **kwargs)\n",
        "    model = myResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model_dict = model.state_dict()\n",
        "        pre_train_model = model_zoo.load_url(model_urls['resnet101'])\n",
        "        pre_train_model = {k:v for k,v in pre_train_model.items() if k in model_dict}\n",
        "        model_dict.update(pre_train_model)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def myresnet152(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"myResNet-152 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    # return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,\n",
        "    #                **kwargs)\n",
        "    model = myResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model_dict = model.state_dict()\n",
        "        pre_train_model = model_zoo.load_url(model_urls['resnet152'])\n",
        "        pre_train_model = {k:v for k,v in pre_train_model.items() if k in model_dict}\n",
        "        model_dict.update(pre_train_model)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def myresnext50_32x4d(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNeXt-50 32x4d model from\n",
        "    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    kwargs['groups'] = 32\n",
        "    kwargs['width_per_group'] = 4\n",
        "    #return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],\n",
        "       #            pretrained, progress, **kwargs)\n",
        "    model = myResNet(Bottleneck, [3, 4, 6, 3],\n",
        "                   pretrained, progress, **kwargs)\n",
        "    if pretrained:\n",
        "        model_dict = model.state_dict()\n",
        "        pre_train_model = model_zoo.load_url(model_urls['resnext50_32x4d'])\n",
        "        pre_train_model = {k:v for k,v in pre_train_model.items() if k in model_dict}\n",
        "        model_dict.update(pre_train_model)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def myresnext101_32x8d(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNeXt-101 32x8d model from\n",
        "    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    kwargs['groups'] = 32\n",
        "    kwargs['width_per_group'] = 8\n",
        "    # return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],\n",
        "    #                pretrained, progress, **kwargs)\n",
        "    model = myResNet(Bottleneck, [3, 4, 23, 3],\n",
        "                   pretrained, progress, **kwargs)\n",
        "    if pretrained:\n",
        "        model_dict = model.state_dict()\n",
        "        pre_train_model = model_zoo.load_url(model_urls['resnext101_32x8d'])\n",
        "        pre_train_model = {k:v for k,v in pre_train_model.items() if k in model_dict}\n",
        "        model_dict.update(pre_train_model)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def mywide_resnet50_2(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"Wide ResNet-50-2 model from\n",
        "    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n",
        "    The model is the same as ResNet except for the bottleneck number of channels\n",
        "    which is twice larger in every block. The number of channels in outer 1x1\n",
        "    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
        "    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    kwargs['width_per_group'] = 64 * 2\n",
        "    return _resnet('wide_resnet50_2', Bottleneck, [3, 4, 6, 3],\n",
        "                   pretrained, progress, **kwargs)\n",
        "\n",
        "\n",
        "def mywide_resnet101_2(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"Wide ResNet-101-2 model from\n",
        "    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n",
        "    The model is the same as ResNet except for the bottleneck number of channels\n",
        "    which is twice larger in every block. The number of channels in outer 1x1\n",
        "    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n",
        "    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    kwargs['width_per_group'] = 64 * 2\n",
        "    return _resnet('wide_resnet101_2', Bottleneck, [3, 4, 23, 3],\n",
        "                   pretrained, progress, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKp6uKbFLEi8"
      },
      "source": [
        "# Define the DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAWjSqmmLGwN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch\n",
        "from torch.utils import data\n",
        "\n",
        "\n",
        "class VideoDataset_NR_image_with_fast_features(data.Dataset):\n",
        "    \"\"\"Read data from the original dataset for feature extraction\"\"\"\n",
        "    def __init__(self, data_dir, data_dir_3D , datainfo_path, transform, crop_size, frame_index=1, video_length_read = 4):\n",
        "        super(VideoDataset_NR_image_with_fast_features, self).__init__()\n",
        "\n",
        "        # column_names = ['vid_name', 'scene', 'dis_type_level']\n",
        "        dataInfo = pd.read_csv(datainfo_path, header = 0, sep=',', index_col=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "        self.video_names = dataInfo['name']\n",
        "        self.moss = dataInfo['mos']\n",
        "\n",
        "        self.crop_size = crop_size\n",
        "        self.data_dir = data_dir\n",
        "        self.data_dir_3D = data_dir_3D\n",
        "        self.transform = transform\n",
        "        self.length = len(self.video_names)\n",
        "        self.frame_index = frame_index\n",
        "        self.video_length_read = video_length_read\n",
        "        self.items = []\n",
        "        for idx in range(0, len(self.video_names)):\n",
        "          video_name = self.video_names.iloc[idx]\n",
        "          frames_dir = os.path.join(self.data_dir, video_name)\n",
        "\n",
        "          video_channel = 3\n",
        "          video_height_crop = self.crop_size\n",
        "          video_width_crop = self.crop_size\n",
        "\n",
        "          video_length_read = self.video_length_read\n",
        "          transformed_video = torch.zeros([video_length_read, video_channel, video_height_crop, video_width_crop])\n",
        "\n",
        "          video_read_index = 0\n",
        "          for i in range(video_length_read):\n",
        "              # select the j-th frame every 30 frames\n",
        "              imge_name = os.path.join(frames_dir, str(self.frame_index+i*30).zfill(3) + '.png')\n",
        "              if os.path.exists(imge_name):\n",
        "                  read_frame = Image.open(imge_name)\n",
        "                  read_frame = read_frame.convert('RGB')\n",
        "                  read_frame = self.transform(read_frame)\n",
        "                  transformed_video[i] = read_frame\n",
        "\n",
        "                  video_read_index += 1\n",
        "              else:\n",
        "                  print(imge_name)\n",
        "                  print('Image do not exist!')\n",
        "\n",
        "          if video_read_index < video_length_read:\n",
        "              for j in range(video_read_index, video_length_read):\n",
        "                  transformed_video[j] = transformed_video[video_read_index-1]\n",
        "\n",
        "          # read 3D features\n",
        "          feature_folder_name = os.path.join(self.data_dir_3D, video_name.split('.')[0])\n",
        "          transformed_feature = torch.zeros([video_length_read, 256])\n",
        "          for i in range(video_length_read):\n",
        "              feature_3D = np.load(os.path.join(feature_folder_name, 'feature_' + str(i) + '_fast_feature.npy'))\n",
        "              feature_3D = torch.from_numpy(feature_3D)\n",
        "              feature_3D = feature_3D.squeeze()\n",
        "              transformed_feature[i] = feature_3D\n",
        "\n",
        "          self.items.append([transformed_video, transformed_feature])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return *self.items[idx], self.moss.iloc[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBEKPR3Vp9T7"
      },
      "source": [
        "# FastAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lsywl6oJLrT4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import sys\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "\n",
        "required = {'nbdev', 'fastbook'}\n",
        "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
        "missing = required - installed\n",
        "print(missing)\n",
        "\n",
        "if 'nbdev' in missing:\n",
        "    print(\"INSTALLING nbdev\")\n",
        "    !pip install nbdev\n",
        "!pip list |grep nbdev\n",
        "if 'fastbook' in missing:\n",
        "    print(\"INSTALLING fastbook\")\n",
        "    !pip install -Uqq fastbook\n",
        "!pip list |grep fastbook\n",
        "\n",
        "from fastai import *\n",
        "from fastai.vision import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV-Sk4BvPejj"
      },
      "outputs": [],
      "source": [
        "# Now we SET UP Fastai\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "import fastai\n",
        "import fastcore\n",
        "print(f'fastcore version {fastcore.__version__} installed')\n",
        "print(f'fastai version {fastai.__version__} installed')\n",
        "from nbdev.showdoc import *\n",
        "from fastai.vision.all import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBCzHgvETipc"
      },
      "outputs": [],
      "source": [
        "@patch\n",
        "@delegates(subplots)\n",
        "def plot_metrics(self: Recorder, nrows=None, ncols=None, figsize=None, fname='resultado.png',**kwargs):\n",
        "    metrics = np.stack(self.values)\n",
        "    names = self.metric_names[1:-1]\n",
        "    n = len(names) - 1\n",
        "    if nrows is None and ncols is None:\n",
        "        nrows = int(math.sqrt(n))\n",
        "        ncols = int(np.ceil(n / nrows))\n",
        "    elif nrows is None: nrows = int(np.ceil(n / ncols))\n",
        "    elif ncols is None: ncols = int(np.ceil(n / nrows))\n",
        "    figsize = figsize or (ncols * 6, nrows * 4)\n",
        "    fig, axs = subplots(nrows, ncols, figsize=figsize, **kwargs)\n",
        "    axs = [ax if i < n else ax.set_axis_off() for i, ax in enumerate(axs.flatten())][:n]\n",
        "    for i, (name, ax) in enumerate(zip(names, [axs[0]] + axs)):\n",
        "        ax.plot(metrics[:, i], color='#1f77b4' if i == 0 else '#ff7f0e', label='valid' if i > 0 else 'train')\n",
        "        ax.set_title(name if i > 1 else 'losses')\n",
        "        ax.legend(loc='best')\n",
        "    plt.show()\n",
        "    plt.savefig(fname=fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tEobOVykn_S"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1ztvJTZkqTd"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from fastai.callback.wandb import *\n",
        "wandb.login(relogin=True, key='...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BEZ5V7Op_cw"
      },
      "outputs": [],
      "source": [
        "!cp /content/gdrive/MyDrive/VQA_PC.zip /content\n",
        "!unzip -q -x VQA_PC.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik0_PXRO2szv"
      },
      "outputs": [],
      "source": [
        "%cd /content/VQA_PC/extraction\n",
        "!unzip -q -x our_data_features.zip\n",
        "%cd /content/VQA_PC/rotation\n",
        "!unzip -q -x ourdata.zip\n",
        "!unzip -q -x ourdata_resized.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7asUDbwVafe"
      },
      "outputs": [],
      "source": [
        "%cd /content/VQA_PC/main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQemI_utLKc2"
      },
      "source": [
        "# Define the Dataloader function and the base config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxUeLQEuLKHH"
      },
      "outputs": [],
      "source": [
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "config = {\n",
        "    'database': 'SJTU',\n",
        "    'conv_base_lr': 0.00004,\n",
        "    'decay_ratio': 0.9,\n",
        "    'decay_interval': 10,\n",
        "    'train_batch_size': 32,\n",
        "    'num_workers': 2,\n",
        "    'epochs': 30,\n",
        "    'split_num': 9,\n",
        "    'crop_size': 224,\n",
        "    'frame_index': 5,\n",
        "    'video_length_read': 4,\n",
        "    'pretrained_model_path': 'ckpts/ResNet_mean_with_fast_LSPCQA_1_best.pth',\n",
        "    'feature_fusion_method': 0\n",
        "    }\n",
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "\n",
        "config = dotdict(config)\n",
        "\n",
        "\n",
        "def get_dataloader(config: dict, split: int = 0):\n",
        "  transformations_train = transforms.Compose([transforms.RandomCrop(224),transforms.ToTensor(),\\\n",
        "  transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
        "  transformations_test = transforms.Compose([transforms.CenterCrop(224),transforms.ToTensor(),\\\n",
        "  transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n",
        "\n",
        "  if config.database == 'SJTU':\n",
        "    images_dir = 'database/sjtu_2d/'\n",
        "    datainfo_train = 'database/sjtu_data_info/train_' + str(split+1) +'.csv'\n",
        "    datainfo_test = 'database/sjtu_data_info/test_' + str(split+1) +'.csv'\n",
        "    data_3d_dir = 'database/sjtu_slowfast/'\n",
        "  elif config.database == 'SJTU_resized':\n",
        "    images_dir = 'database/sjtu_2d_resized/'\n",
        "    datainfo_train = 'database/sjtu_data_info/train_' + str(split+1) +'.csv'\n",
        "    datainfo_test = 'database/sjtu_data_info/test_' + str(split+1) +'.csv'\n",
        "    data_3d_dir = 'database/sjtu_slowfast/'\n",
        "  elif config.database == 'WPC':\n",
        "    images_dir = 'database/wpc_2d/'\n",
        "    datainfo_train = 'database/wpc_data_info/train_' + str(split+1) +'.csv'\n",
        "    datainfo_test = 'database/wpc_data_info/test_' + str(split+1) +'.csv'\n",
        "    data_3d_dir = 'database/wpc_slowfast/'\n",
        "  elif 'LS_SJTU' in config.database:\n",
        "    images_dir = '../rotation/imgs/'\n",
        "    datainfo_train = 'database/ls_sjtu_data_info/train_' + str(split+1) +'.csv'\n",
        "    datainfo_test = 'database/ls_sjtu_data_info/test_' + str(split+1) +'.csv'\n",
        "    data_3d_dir = '../extraction/ls_sjtu_features/'\n",
        "    if 'SCALED' in config.database:\n",
        "      datainfo_train = 'database/ls_sjtu_data_info_scaled/train_' + str(split+1) +'.csv'\n",
        "      datainfo_test = 'database/ls_sjtu_data_info_scaled/test_' + str(split+1) +'.csv'\n",
        "  elif 'OURDATA' in config.database:\n",
        "    images_dir = '../rotation/ourimgs/'\n",
        "    datainfo_train = 'database/our_data_info/train_' + str(split+1) +'.csv'\n",
        "    datainfo_test = 'database/our_data_info/test_' + str(split+1) +'.csv'\n",
        "    data_3d_dir = '../extraction/our_data_features/'\n",
        "    if 'SCALED' in config.database:\n",
        "      datainfo_train = 'database/our_data_info_scaled/train_' + str(split+1) +'.csv'\n",
        "      datainfo_test = 'database/our_data_info_scaled/test_' + str(split+1) +'.csv'\n",
        "    if 'RESIZED' in config.database:\n",
        "      images_dir = '../rotation/ourimgs_resized/'\n",
        "\n",
        "  trainset = VideoDataset_NR_image_with_fast_features(images_dir, data_3d_dir, datainfo_train, transformations_train, crop_size=config.crop_size,frame_index=config.frame_index,video_length_read = config.video_length_read)\n",
        "  testset = VideoDataset_NR_image_with_fast_features(images_dir, data_3d_dir, datainfo_test, transformations_test, crop_size=config.crop_size,frame_index=config.frame_index,video_length_read = config.video_length_read)\n",
        "\n",
        "  train_loader = DataLoader(trainset, batch_size=config.train_batch_size, n_inp=2,\n",
        "                            shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
        "\n",
        "  val_loader = TfmdDL(testset, batch_size=1, n_inp=2,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
        "  dls =  fastai.data.core.DataLoaders(train_loader, val_loader, device=\"cuda\")\n",
        "  dls.train.n_inp=2\n",
        "  # dls.valid.n_inp=2\n",
        "\n",
        "  return dls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KOEIKwVkloT"
      },
      "source": [
        "# K-fold + logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QMgwE9tdpH5"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import gc\n",
        "def clean_gpu_memory():\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "\n",
        "clean_gpu_memory()\n",
        "\n",
        "def kfold_model(dls_config: dict, model_func, optimizer, kfold: int = 9, n_epoch: int = 15,\n",
        "                model_name: str = 'MVQAPC_model', project_name: str = 'MVQAPC',\n",
        "                group: str = 'quality',\n",
        "                dataset: str = 'SJTU-PCQA', architecture: str = 'PLAIN',\n",
        "                leslie: bool = False):\n",
        "  with wandb.init(\n",
        "      project=project_name,\n",
        "      group=group,\n",
        "      config=\n",
        "      {\n",
        "      \"architecture\": architecture,\n",
        "      \"dataset\": dataset,\n",
        "      \"epochs\": n_epoch,\n",
        "      \"optimizer\": optimizer,\n",
        "      \"leslie\": leslie\n",
        "      },\n",
        "      dir='/content'\n",
        "                  ) as run:\n",
        "    config = wandb.config\n",
        "    srocc = SpearmanCorrCoef()\n",
        "    cbs = [EarlyStoppingCallback(monitor='valid_loss', patience=6)]\n",
        "    metrics = [rmse, srocc]\n",
        "    dls = get_dataloader(dls_config, config.kfold)\n",
        "    learn = Learner(dls, model_func(), metrics=metrics,loss_func = MSELossFlat())\n",
        "    if leslie:\n",
        "      lr = learn.lr_find(show_plot=False)\n",
        "      train_func = functools.partial(learn.fit_one_cycle, lr_max=lr[0])\n",
        "    else:\n",
        "      train_func = functools.partial(learn.fit, lr=dls_config.conv_base_lr)\n",
        "\n",
        "    train_func(n_epoch=n_epoch,\n",
        "                 cbs=cbs+[WandbCallback(log_preds_every_epoch=True,\n",
        "                                        model_name=f'{model_name}_{config.kfold}',\n",
        "                                        dataset_name=dataset\n",
        "                                        )\n",
        "                                ],\n",
        "              )\n",
        "    del dls, learn\n",
        "    clean_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCX-b6vCGyvD"
      },
      "outputs": [],
      "source": [
        "def get_pretrained(method: int = 0, path: str = 'ckpts/ResNet_mean_with_fast_LSPCQA_1_best.pth'):\n",
        "  model_pretrained = myresnet50(pretrained=False,feature_fusion_method=method)\n",
        "  model_pretrained.load_state_dict(torch.load(path))\n",
        "  return model_pretrained\n",
        "\n",
        "#model_fusion_0 = myresnet50(pretrained=True, feature_fusion_method=0)\n",
        "def get_feature_fusion(method: int = 1):\n",
        "  model = myresnet50(pretrained=True, feature_fusion_method=method)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVO_D0Lh-oOe"
      },
      "outputs": [],
      "source": [
        "def get_basic_ourdata_config():\n",
        "  config = {\n",
        "      'database': 'OURDATA',\n",
        "      'conv_base_lr': 0.00004,\n",
        "      'decay_ratio': 0.9,\n",
        "      'decay_interval': 10,\n",
        "      'train_batch_size': 32,\n",
        "      'num_workers': 2,\n",
        "      'epochs': 30,\n",
        "      'split_num': 11,\n",
        "      'crop_size': 224,\n",
        "      'frame_index': 5,\n",
        "      'video_length_read': 4,\n",
        "      'pretrained_model_path': 'ckpts/ResNet_mean_with_fast_LSPCQA_1_best.pth',\n",
        "      'feature_fusion_method': 0\n",
        "      }\n",
        "  config = dotdict(config)\n",
        "  return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVNU_uMtG0b6"
      },
      "outputs": [],
      "source": [
        "def get_sweep_config(split_num):\n",
        "  PROJECT_NAME = 'MVQAPC'\n",
        "\n",
        "  sweep_config = {\n",
        "      'method': 'grid'\n",
        "      }\n",
        "  metric = {\n",
        "      'name': 'rmse',\n",
        "      'goal': 'minimize'\n",
        "      }\n",
        "\n",
        "  sweep_config['metric'] = metric\n",
        "  parameters_dict = {\n",
        "      'kfold': {\n",
        "          'values': [i for i in range(split_num)]\n",
        "          },\n",
        "      }\n",
        "  sweep_config['parameters'] = parameters_dict\n",
        "  return sweep_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IICoimXKYrNe"
      },
      "source": [
        "# Replicando resultados sobre SJTU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8z0mxHu9Sdj"
      },
      "source": [
        "# Starting executing stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQJebRd_Y0Xi"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "model_func = functools.partial(myresnet50,pretrained=True,feature_fusion_method=0)\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=model_func,\n",
        "  optimizer=Adam,\n",
        "  model_name='Scratch_SJTU',\n",
        "  dataset='SJTU',\n",
        "  n_epoch=30,\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj-vbgBc-jBn"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "model_func = functools.partial(myresnet50,pretrained=True,feature_fusion_method=0)\n",
        "config.update({'database': 'SJTU_resized'})\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=model_func,\n",
        "  optimizer=Adam,\n",
        "  model_name='Scratch_SJTU_resized',\n",
        "  dataset='SJTU_resized',\n",
        "  n_epoch=30,\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p71KaV-jYdb1"
      },
      "source": [
        "# Comparaci√≥n entre modelos sobre OurData\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuOtMQajYGvl"
      },
      "outputs": [],
      "source": [
        "%cd /content/VQA_PC/main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbGkVxS-j6z5"
      },
      "source": [
        "## Pretrained SJTU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ1qDZZMKQsQ"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC',\n",
        "  dataset='OURDATA',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7s45YTt9lGd"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_SCALED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_scaled',\n",
        "  dataset='OURDATA_SCALED',\n",
        "  group='ScaledLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAUKFA39VOhi"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_SCALED_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_scaled',\n",
        "  dataset='OURDATA_SCALED_RESIZED',\n",
        "  group='ResizedScaledLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORP95gRvdzQY"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXbCsgrcnQYU"
      },
      "source": [
        "## Feature Fusion 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6zjP8uHmzaZ"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=functools.partial(get_feature_fusion, 0),\n",
        "  optimizer=Adam,\n",
        "  model_name='MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED',\n",
        "  group='FeatureFusion0',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrShySdb9dUB"
      },
      "source": [
        "## Feature Fusion 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ss0yV2KxKYEP"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(model_func=functools.partial(get_feature_fusion, 1),\n",
        "                 model_name='FeatureFusion1_MVQAPC', group='FeatureFusion1'))\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfWxD2R7E9GX"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_SCALED_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_RS',\n",
        "  dataset='OURDATA_SCALED_RESIZED',\n",
        "  group='ResizedScaledLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(model_func=functools.partial(get_feature_fusion, 1),\n",
        "                 model_name='FeatureFusion1_MVQAPC', group='FeatureFusion1'))\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GYWLg4LcNFQ"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(model_func=functools.partial(get_feature_fusion, 1),\n",
        "                 model_name='FeatureFusion1_MVQAPC', group='FeatureFusion1'))\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZTCyAO7LCPD"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_SCALED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_SCALED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(model_func=functools.partial(get_feature_fusion, 1),\n",
        "                 model_name='FeatureFusion1_MVQAPC', group='FeatureFusion1'))\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrQ52uEW9fGm"
      },
      "source": [
        "## Feature Fusion 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-TzC51yKYf_"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(model_func=functools.partial(get_feature_fusion, 2), model_name='FeatureFusion2_MVQAPC', group='FeatureFusion2'))\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fg9XXa13FXh9"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_SCALED_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_SCALED_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(model_func=functools.partial(get_feature_fusion, 2), model_name='FeatureFusion2_MVQAPC', group='FeatureFusion2'))\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZYYNHstEpiU"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(model_func=functools.partial(get_feature_fusion, 2), model_name='FeatureFusion2_MVQAPC', group='FeatureFusion2'))\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SM2Os84_LKwD"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_SCALED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_SCALED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(model_func=functools.partial(get_feature_fusion, 2), model_name='FeatureFusion2_MVQAPC', group='FeatureFusion2'))\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jC358gZ9gjc"
      },
      "source": [
        "## Feature fusion 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iq1VhODUKa0P"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(model_func=functools.partial(get_feature_fusion, 3), model_name='FeatureFusion3_MVQAPC', group='FeatureFusion3'))\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmUYD1YnF4PS"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_SCALED_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_SCALED_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(model_func=functools.partial(get_feature_fusion, 3), model_name='FeatureFusion3_MVQAPC', group='FeatureFusion3'))\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVzLTMbuEwsv"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(model_func=functools.partial(get_feature_fusion, 3), model_name='FeatureFusion3_MVQAPC', group='FeatureFusion3'))\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcXa-QNtLSWv"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_SCALED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_SCALED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(model_func=functools.partial(get_feature_fusion, 3), model_name='FeatureFusion3_MVQAPC', group='FeatureFusion3'))\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LVgFM4Tji7L"
      },
      "source": [
        "# pretrain in LS-SJTU-PCQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPn8DKBMkRNS"
      },
      "outputs": [],
      "source": [
        "%cd /content/VQA_PC/extraction\n",
        "!unzip -q -x ls_sjtu_features.zip\n",
        "%cd /content/VQA_PC/rotation\n",
        "!unzip -q -x LS-SJTU-PCQA.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lRzjtd9w8Uq"
      },
      "outputs": [],
      "source": [
        "%cd /content/VQA_PC/main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4ym1W-N6Xfz"
      },
      "source": [
        "## No Leslie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEBrXwUhjqP1"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'LS_SJTU_SCALED'\n",
        "model = get_feature_fusion(0)\n",
        "dls = get_dataloader(config, 0)\n",
        "srocc = SpearmanCorrCoef()\n",
        "cbs = [EarlyStoppingCallback(monitor='spearmanr', patience=6), SaveModelCallback(monitor='spearmanr', fname='feature0')]\n",
        "metrics = [rmse, srocc]\n",
        "learn = Learner(dls, model,  metrics=metrics, loss_func=MSELossFlat(), path='/content/gdrive/MyDrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSLZ3Is1xByv"
      },
      "outputs": [],
      "source": [
        "learn.fit(30, lr=config.conv_base_lr, cbs=cbs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mm6dvRcv4QwQ"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'LS_SJTU_SCALED'\n",
        "model = get_feature_fusion(1)\n",
        "dls = get_dataloader(config, 0)\n",
        "srocc = SpearmanCorrCoef()\n",
        "cbs = [EarlyStoppingCallback(monitor='spearmanr', patience=6), SaveModelCallback(monitor='spearmanr', fname='feature1')]\n",
        "metrics = [rmse, srocc]\n",
        "learn = Learner(dls, model,  metrics=metrics, loss_func=MSELossFlat(), path='/content/gdrive/MyDrive/')\n",
        "learn.fit(30, lr=config.conv_base_lr, cbs=cbs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtGXI-484Tnr"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'LS_SJTU_SCALED'\n",
        "model = get_feature_fusion(2)\n",
        "dls = get_dataloader(config, 0)\n",
        "srocc = SpearmanCorrCoef()\n",
        "cbs = [EarlyStoppingCallback(monitor='spearmanr', patience=6), SaveModelCallback(monitor='spearmanr', fname='feature2')]\n",
        "metrics = [rmse, srocc]\n",
        "learn = Learner(dls, model,  metrics=metrics, loss_func=MSELossFlat(), path='/content/gdrive/MyDrive/')\n",
        "learn.fit(30, lr=config.conv_base_lr, cbs=cbs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMMZ2mt04XBL"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'LS_SJTU_SCALED'\n",
        "model = get_feature_fusion(3)\n",
        "dls = get_dataloader(config, 0)\n",
        "srocc = SpearmanCorrCoef()\n",
        "cbs = [EarlyStoppingCallback(monitor='spearmanr', patience=6), SaveModelCallback(monitor='spearmanr', fname='feature3')]\n",
        "metrics = [rmse, srocc]\n",
        "learn = Learner(dls, model,  metrics=metrics, loss_func=MSELossFlat(), path='/content/gdrive/MyDrive/')\n",
        "learn.fit(30, lr=config.conv_base_lr, cbs=cbs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZWKnumR0hs5"
      },
      "source": [
        "# Fine Tune From LS-SJTU-PCQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiNrB2S9Cx2U"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import glob\n",
        "import os\n",
        "\n",
        "objs = glob.glob('/content/VQA_PC/main/database/our_data_info_norm/*.csv')\n",
        "print(objs)\n",
        "for obj in objs:\n",
        "  df = pl.read_csv(obj)\n",
        "  name = os.path.basename(obj)\n",
        "  df = df.select(pl.col('name'),pl.col('mos').apply(lambda x: 1-x).mul(5))\n",
        "  df.write_csv(f'/content/VQA_PC/main/database/our_data_info_scaled/{name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmLiIIeHh7Vk"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(\n",
        "    model_func=functools.partial(get_pretrained,\n",
        "                                 method=0,\n",
        "                                 path='/content/gdrive/MyDrive/models/feature0.pth'\n",
        "                                 ), model_name='LS-SJTU-F0-v3',\n",
        "    group='LS-SJTU-F0-v3')\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7emzJmFdC4SA"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED_SCALED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED_SCALED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(\n",
        "    model_func=functools.partial(get_pretrained,\n",
        "                                 method=0,\n",
        "                                 path='/content/gdrive/MyDrive/models/feature0.pth'\n",
        "                                 ), model_name='LS-SJTU-F0-v3',\n",
        "    group='LS-SJTU-F0-v3')\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XbY24RS1jxW"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(\n",
        "    model_func=functools.partial(get_pretrained,\n",
        "                                 method=1,\n",
        "                                 path='/content/gdrive/MyDrive/models/feature1.pth'\n",
        "                                 ), model_name='LS-SJTU-F1-v3',\n",
        "    group='LS-SJTU-F1-v3')\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED_SCALED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED_SCALED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(\n",
        "    model_func=functools.partial(get_pretrained,\n",
        "                                 method=1,\n",
        "                                 path='/content/gdrive/MyDrive/models/feature1.pth'\n",
        "                                 ), model_name='LS-SJTU-F1-v3',\n",
        "    group='LS-SJTU-F1-v3')\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ],
      "metadata": {
        "id": "jSejvYLhJ2nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(\n",
        "    model_func=functools.partial(get_pretrained,\n",
        "                                 method=2,\n",
        "                                 path='/content/gdrive/MyDrive/models/feature2.pth'\n",
        "                                 ), model_name='LS-SJTU-F2-v3',\n",
        "    group='LS-SJTU-F2-v3')\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ],
      "metadata": {
        "id": "n3XKFhx2JrOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED_SCALED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED_SCALED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(\n",
        "    model_func=functools.partial(get_pretrained,\n",
        "                                 method=2,\n",
        "                                 path='/content/gdrive/MyDrive/models/feature2.pth'\n",
        "                                 ), model_name='LS-SJTU-F2-v3',\n",
        "    group='LS-SJTU-F2-v3')\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ],
      "metadata": {
        "id": "MBBm3w1DKCs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwzSSbB1Jl4e"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(\n",
        "    model_func=functools.partial(get_pretrained,\n",
        "                                 method=3,\n",
        "                                 path='/content/gdrive/MyDrive/models/feature3.pth'\n",
        "                                 ), model_name='LS-SJTU-F3-v3',\n",
        "    group='LS-SJTU-F3-v3')\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqX1OL7PLpHm"
      },
      "source": [
        "## Leslie + LS-SJTU-PCQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzKcSU7wVsZB"
      },
      "outputs": [],
      "source": [
        "config= get_basic_ourdata_config()\n",
        "config.database = 'LS_SJTU_SCALED'\n",
        "model = get_feature_fusion(0)\n",
        "dls = get_dataloader(config, 0)\n",
        "srocc = SpearmanCorrCoef()\n",
        "cbs = [EarlyStoppingCallback(monitor='spearmanr', patience=6), SaveModelCallback(monitor='spearmanr', fname='Lesliefeature0')]\n",
        "metrics = [rmse, srocc]\n",
        "learn = Learner(dls, model,  metrics=metrics, loss_func=MSELossFlat(), path='/content/gdrive/MyDrive/')\n",
        "lr = learn.lr_find(show_plot=False)\n",
        "learn.fit_one_cycle(30, lr_max=lr[0], cbs=cbs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpt7H5OL5s5z"
      },
      "outputs": [],
      "source": [
        "config= get_basic_ourdata_config()\n",
        "config.database = 'LS_SJTU_SCALED'\n",
        "model = get_feature_fusion(1)\n",
        "dls = get_dataloader(config, 0)\n",
        "srocc = SpearmanCorrCoef()\n",
        "cbs = [EarlyStoppingCallback(monitor='spearmanr', patience=6), SaveModelCallback(monitor='spearmanr', fname='Lesliefeature1')]\n",
        "metrics = [rmse, srocc]\n",
        "learn = Learner(dls, model,  metrics=metrics, loss_func=MSELossFlat(), path='/content/gdrive/MyDrive/')\n",
        "lr = learn.lr_find(show_plot=False)\n",
        "learn.fit_one_cycle(30, lr_max=lr[0], cbs=cbs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSr8IIwC51_O"
      },
      "outputs": [],
      "source": [
        "config= get_basic_ourdata_config()\n",
        "config.database = 'LS_SJTU_SCALED'\n",
        "model = get_feature_fusion(2)\n",
        "dls = get_dataloader(config, 0)\n",
        "srocc = SpearmanCorrCoef()\n",
        "cbs = [EarlyStoppingCallback(monitor='spearmanr', patience=6), SaveModelCallback(monitor='spearmanr', fname='Lesliefeature2')]\n",
        "metrics = [rmse, srocc]\n",
        "learn = Learner(dls, model,  metrics=metrics, loss_func=MSELossFlat(), path='/content/gdrive/MyDrive/')\n",
        "lr = learn.lr_find(show_plot=False)\n",
        "learn.fit_one_cycle(30, lr_max=lr[0], cbs=cbs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uosP9Rsk55YP"
      },
      "outputs": [],
      "source": [
        "config= get_basic_ourdata_config()\n",
        "config.database = 'LS_SJTU_SCALED'\n",
        "model = get_feature_fusion(3)\n",
        "dls = get_dataloader(config, 0)\n",
        "srocc = SpearmanCorrCoef()\n",
        "cbs = [EarlyStoppingCallback(monitor='spearmanr', patience=6), SaveModelCallback(monitor='spearmanr', fname='Lesliefeature3')]\n",
        "metrics = [rmse, srocc]\n",
        "learn = Learner(dls, model,  metrics=metrics, loss_func=MSELossFlat(), path='/content/gdrive/MyDrive/')\n",
        "lr = learn.lr_find(show_plot=False)\n",
        "learn.fit_one_cycle(30, lr_max=lr[0], cbs=cbs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnFr1EZbD6Ca"
      },
      "source": [
        "## Leslie Finetune OurData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZkGG-I1Yci2"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import glob\n",
        "import os\n",
        "\n",
        "objs = glob.glob('/content/VQA_PC/main/database/our_data_info_norm/*.csv')\n",
        "print(objs)\n",
        "for obj in objs:\n",
        "  df = pl.read_csv(obj)\n",
        "  name = os.path.basename(obj)\n",
        "  df = df.select(pl.col('name'),pl.col('mos').apply(lambda x: 1-x).mul(5))\n",
        "  df.write_csv(f'/content/VQA_PC/main/database/our_data_info_scaled/{name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn-4WxNJD8Gj"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED_SCALED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(\n",
        "    model_func=functools.partial(get_pretrained,\n",
        "                                 method=0,\n",
        "                                 path='/content/gdrive/MyDrive/models/Lesliefeature0.pth'\n",
        "                                 ), model_name='LS-SJTU-LESLIE-F0-v2',\n",
        "    group='LS-SJTU-LESLIE-F0-v2')\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfD689T5EGG8"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(\n",
        "    model_func=functools.partial(get_pretrained,\n",
        "                                 method=1,\n",
        "                                 path='/content/gdrive/MyDrive/models/Lesliefeature1.pth'\n",
        "                                 ), model_name='LS-SJTU-LESLIE-F1-v2',\n",
        "    group='LS-SJTU-LESLIE-F1-v2')\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ztnbErZR2RY"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED_SCALED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED_SCALED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(\n",
        "    model_func=functools.partial(get_pretrained,\n",
        "                                 method=1,\n",
        "                                 path='/content/gdrive/MyDrive/models/Lesliefeature1.pth'\n",
        "                                 ), model_name='LS-SJTU-LESLIE-F1-v2',\n",
        "    group='LS-SJTU-LESLIE-F1-v2')\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yotC79nEX3F"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(\n",
        "    model_func=functools.partial(get_pretrained,\n",
        "                                 method=2,\n",
        "                                 path='/content/gdrive/MyDrive/models/Lesliefeature2.pth'\n",
        "                                 ), model_name='LS-SJTU-LESLIE-F2-v2',\n",
        "    group='LS-SJTU-LESLIE-F2-v2')\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZHBuluGEcIz"
      },
      "outputs": [],
      "source": [
        "config = get_basic_ourdata_config()\n",
        "config.database = 'OURDATA_RESIZED'\n",
        "body = dict(\n",
        "  dls_config=config,\n",
        "  model_func=get_pretrained,\n",
        "  optimizer=Adam,\n",
        "  model_name='Pretrained_MVQAPC_resized',\n",
        "  dataset='OURDATA_RESIZED',\n",
        "  group='ResizedLabels',\n",
        "  n_epoch=30,\n",
        "  leslie=False\n",
        ")\n",
        "body.update(dict(\n",
        "    model_func=functools.partial(get_pretrained,\n",
        "                                 method=3,\n",
        "                                 path='/content/gdrive/MyDrive/models/Lesliefeature3.pth'\n",
        "                                 ), model_name='LS-SJTU-LESLIE-F3-v2',\n",
        "    group='LS-SJTU-LESLIE-F3-v2')\n",
        ")\n",
        "sweep_config = get_sweep_config(config.split_num)\n",
        "polysweep_train = functools.partial(kfold_model, **body)\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='MVQAPC')\n",
        "wandb.agent(sweep_id,\n",
        "            polysweep_train, count=config.split_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faQPGCs5Uzy4"
      },
      "source": [
        "# Before Quitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh5FOdpOUxTC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "F8z0mxHu9Sdj",
        "GbGkVxS-j6z5",
        "VXbCsgrcnQYU",
        "wrShySdb9dUB",
        "xrQ52uEW9fGm",
        "_jC358gZ9gjc",
        "3LVgFM4Tji7L",
        "k4ym1W-N6Xfz"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}